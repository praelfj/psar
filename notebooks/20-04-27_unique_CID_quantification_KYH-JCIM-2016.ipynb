{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# unique CID quantificaton\n",
    "quantifying unique CIDs to reproduce the following paper: Helal, Kazi Yasin, et al. \"Public domain HTS fingerprints: design and evaluation of compound bioactivity profiles from PubChem’s bioassay repository.\" Journal of chemical information and modeling 56.2 (2016): 390-398.\n",
    "\n",
    "\"First, we determined 329 019 compounds that had been tested in at least 250 assays and were kept for our analysis. Second, we identified 284 assays in which at least 288 000 of these retained compounds had been tested. All other assays that had tested fewer compounds were discarded. We then removed 19 counter-screens and 22 assays that did not report primary, single concentration activity values so that, in the end, our final fingerprint assay panel consisted of __243 different assays__ (see Supplementary Data Set S1 for PubChem assay identifiers (AIDs) and descriptions). Molecule standardization identified __redundancies for 244 CIDs__, i.e. the InChI Key that they mapped to was also found for another CID. After CID merging, __328 893 unique molecules__ remained for which PubChem HTSFPs were calculated.\"\n",
    "\n",
    "---\n",
    "## downloading pubchem bioassay files\n",
    "* search was done on pubchem bioassay (https://www.ncbi.nlm.nih.gov/pcassay) by using the __Limits__ search function, as specified in the paper (note: note: they said they got 579 assays, I got 582 - I messed around with the upload date but couldn't get the files below 582 even if I went a year before the publication, so I just downloaded the 3x extra files)\n",
    "> “TotalSidCount from 10,000”, “Chemical”, “Primary Screening”, and “NIH Molecular Libraries Program\"\n",
    "* used _PubChem Assay Download service_ (https://pubchem.ncbi.nlm.nih.gov/assay/assaydownload.cgi) to download compressed data tables\n",
    "* used 7-zip to extract .csv.gz files to .csv files and saved them to the /1-raw/public-domain-fingerprints/ dir\n",
    "\n",
    "---\n",
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## isolate all CIDs that are in >250 assays in the original 582 assays downloaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up imports and initialize dataframe to hold data\n",
    "p = '../data/1-raw/public-domain-fingerprints/'\n",
    "aid_list = os.listdir(p)\n",
    "\n",
    "cids = pd.DataFrame(columns=['PUBCHEM_CID', 'assay_count'])\n",
    "aid_count = 1\n",
    "\n",
    "# loop over data to import, process, and add to the cids DF\n",
    "for f in aid_list:\n",
    "    # import and skip over desc rows\n",
    "    aid = pd.read_csv(p + f, skiprows=[1,2,3])\n",
    "    \n",
    "    # correct CID data type, isolate unique CIDs\n",
    "    cid_series = aid['PUBCHEM_CID'].dropna()\n",
    "    inter_dict = {'PUBCHEM_CID':cid_series.astype(int).unique(),\n",
    "              'current_count':1}\n",
    "    intermediate_CID = pd.DataFrame(inter_dict)\n",
    "    \n",
    "    # merge with cids DF\n",
    "    cids = pd.merge(cids, intermediate_CID, on='PUBCHEM_CID', how='outer')\n",
    "\n",
    "    # add records and clean merged df\n",
    "    cids = cids.fillna(0)\n",
    "    cids['assay_count'] = cids['assay_count'] + cids['current_count']\n",
    "    cids = cids.drop('current_count', axis=1)\n",
    "    \n",
    "    if aid_count%25 == 0:\n",
    "        print('{count} of {total} AIDs processed'.format(count=aid_count,\n",
    "                                                         total=len(aid_list)))\n",
    "    aid_count += 1\n",
    "\n",
    "cids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(cids['assay_count'], kde=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cids.sort_values('assay_count', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_cids = cids.loc[cids['assay_count'] > 250]\n",
    "threshold_cids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp = '../data/0-meta/'\n",
    "threshold_cids = threshold_cids.set_index('PUBCHEM_CID')\n",
    "threshold_cids.to_csv(sp + 'KYHelal-2016-JCIM_unique_cids_thresholded.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the ideal number is 329,019 compounds from the paper, but given the extra 3x screens, the couple hundred compound difference might be accounted for - given the fact that this is a fun project, this is close enough\n",
    "\n",
    "## download SMILES from CIDs\n",
    "use Entrez History Server and PUG-REST to download SMILES from CIDs\n",
    "\n",
    "POST example:\n",
    "> https://pubchem.ncbi.nlm.nih.gov/rest/pug/compound/inchi/cids/JSON<br>\n",
    "with “Content-Type: application/x-www-form-urlencoded” in the request header, and put the string<br>\n",
    "inchi=InChI=1S/C3H8/c1-3-2/h3H2,1-2H3<br>\n",
    "in the POST body. (With InChI this looks a little weird, because the first “inchi=” is the name of the PUG REST argument, and the second “InChI=” is part of the InChI string itself.) You should get back CID 6334 (propane)\n",
    "\n",
    "Entrez History Server - PUG-REST workflow example<br>\n",
    "Script #3<br>\n",
    "https://pubchemdocs.ncbi.nlm.nih.gov/pug-rest$example_scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import requests\n",
    "import xml.etree.ElementTree as ET\n",
    "import io\n",
    "\n",
    "sp = '../data/0-meta/'\n",
    "dl_cids = pd.read_csv(sp + 'KYHelal-2016-JCIM_unique_cids_thresholded.csv')\n",
    "dl_cids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set it so it loops over 10,000 compounds at a time and concats onto a final df\n",
    "\n",
    "# set parameters for iterating through data and concatenating data\n",
    "complete_id_list = dl_cids['PUBCHEM_CID'].values\n",
    "id_len = len(complete_id_list)\n",
    "\n",
    "cpnd_start = 0\n",
    "batch_size = 10000\n",
    "cpnd_end = cpnd_start + batch_size\n",
    "\n",
    "smiles = pd.DataFrame()\n",
    "\n",
    "while cpnd_start < id_len:\n",
    "    # add compound batch to Entrez History Server\n",
    "    db = 'pccompound'\n",
    "    id_list = complete_id_list[cpnd_start:cpnd_end]\n",
    "\n",
    "    id_string = ''\n",
    "    for s in id_list:\n",
    "        id_string = id_string + str(s) + ','\n",
    "    id_string = id_string[:-1]\n",
    "\n",
    "    base = 'https://eutils.ncbi.nlm.nih.gov/entrez/eutils/'\n",
    "    url = base + \"epost.fcgi?db={db}\".format(db = db)\n",
    "\n",
    "    r = requests.post(url, data='id=' + id_string)\n",
    "    content = r.content\n",
    "\n",
    "    root = ET.fromstring(content)\n",
    "    key = root.find('QueryKey').text\n",
    "    web_env = root.find('WebEnv').text\n",
    "\n",
    "    # convert Entrez history into a listkey for PUG-REST\n",
    "    action = \"entrez_to_pug\"\n",
    "    lg_cgi = \"https://pubchem.ncbi.nlm.nih.gov/list_gateway/list_gateway.cgi?\"\n",
    "    lg_url = lg_cgi + 'action={a}&entrez_db={db}&entrez_query_key={key}&entrez_webenv={webenv}'.format(\n",
    "        db=db,\n",
    "        key=key,\n",
    "        webenv=web_env,\n",
    "        a=action\n",
    "    )\n",
    "    \n",
    "    lg_result = requests.get(lg_url).content\n",
    "    root = ET.fromstring(lg_result)\n",
    "    list_size = root.find('Response_list-size').text\n",
    "    listkey = root.find('Response_pug-listkey').text\n",
    "    \n",
    "    # get files via PUG-REST\n",
    "    pugrest = \"https://pubchem.ncbi.nlm.nih.gov/rest/pug/\"\n",
    "    input_listkey = \"compound/listkey/{}/\".format(listkey)\n",
    "    operation ='Property/IsomericSMILES/'\n",
    "    output = 'CSV'\n",
    "\n",
    "    pug_url = pugrest + input_listkey + operation + output\n",
    "    urlData = requests.get(pug_url).content\n",
    "    \n",
    "    # open as in-memory text stream and read into a df\n",
    "    temp_smiles = pd.read_csv(io.StringIO(urlData.decode('utf-8')))\n",
    "    smiles = pd.concat([smiles, temp_smiles], sort=False)\n",
    "    \n",
    "    print('{count} compounds of {total} total compounds converted'.format(count=cpnd_end,\n",
    "                                                                          total=id_len))\n",
    "    cpnd_start += batch_size\n",
    "    cpnd_end = cpnd_start + batch_size\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smiles = smiles.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp = '../data/0-meta/'\n",
    "smiles = smiles.set_index('CID')\n",
    "smiles.to_csv(sp + 'KYHelal-2016-JCIM_unique_cids_SMILES.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## standardize molecules by removing salt and charges and standardizing steroechemistry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:qsar]",
   "language": "python",
   "name": "conda-env-qsar-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
