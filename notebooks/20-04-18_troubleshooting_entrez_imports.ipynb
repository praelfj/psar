{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# troubleshooting importing data from Entrez\n",
    "__goal__: figure out how to use Entrez to query and download data from pubchem bioassay\n",
    "\n",
    "__objectives:__\n",
    "* go through introductory and quick start Entrez guide to figure out how Entrez is working\n",
    "* write a function that imports data sets from a list of Assay IDs\n",
    "* write a function that can find data sets based on certain queries, and download subsets of them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HHHNNNNNNNGGGGGGGGG!!!!!\n",
    "according to the pubchem docs, Entrez is not well suited to downloading tabular bioactivity data: https://pubchemdocs.ncbi.nlm.nih.gov/programmatic-access \n",
    "\n",
    "I, naturally, found this out after re-leaning all the Entrez docs below\n",
    "\n",
    "time to learn how to use the pubchem version of all of this; however, note that I got something working at the bottom that bypasses E-utils entirely, and just downloads using a link I modified off of the PubChem BioAssay GUI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## resources\n",
    "https://www.ncbi.nlm.nih.gov/books/NBK25501/<br>\n",
    "https://www.ncbi.nlm.nih.gov/books/NBK25500/<br>\n",
    "https://www.ncbi.nlm.nih.gov/books/NBK25498/<br>\n",
    "https://www.ncbi.nlm.nih.gov/books/NBK25497/\n",
    "\n",
    "## A General Introduction to the E-utilities\n",
    "https://www.ncbi.nlm.nih.gov/books/NBK25497/\n",
    "\n",
    "### introduction\n",
    "* E-utilities = Entrez Programming Utilities\n",
    "* __E-utilities__ are a set of server-side programs at the NCBI that help you query and retrieve data from the Entrez database system; i.e. they're the interface that allows you to get data from all of the Entrez databases - pubmed, pubchem bio assay, etc.\n",
    "* data is accessed via posting an E-utility URL to the NCBI; any scripting language that can post a URL to the server and interperet the XML response is capable of using this system (e.g. python)\n",
    "\n",
    "### usage guidelines and requirements\n",
    "* data us accessed via the E-utility URL: https://eutils.ncbi.nlm.nih.gov/entrez/eutils/\n",
    "* timing and frequency:\n",
    "    * requests should be limited to <3/second\n",
    "    * large requests should be run on weekends or between 9 PM - 5 AM ET\n",
    "    * violation of these can result your IP address being blocked from using the E-utilities - the guide to getting unblocked is on the website\n",
    "* API keys\n",
    "  * allow for up to 10 requests/second\n",
    "  * are taken from your NCBI account, under the settings page http://www.ncbi.nlm.nih.gov/account/\n",
    "  * to use the API key, include it in the E-utility URL, e.g.: esummary.fcgi?db=pubmed&id=123456&api_key=ABCDE12345\n",
    "* minimizing the number of requests using the Entrez History server\n",
    "    * to decrease request #, especially if you're doing a large query, use Entrez History\n",
    "    * within this method, UID records are stored on a server, and you query the actualy data you're downloading (using the UIDs) in batches to cover the entire dataset\n",
    "* E-utilities URL syntax\n",
    "    * use only lower case\n",
    "    * replace all spaces with \"+\"\n",
    "    * use URL encodings for special characters (e.g. %22 for \")\n",
    "\n",
    "### the nine E-utilities in breif\n",
    "1. EInfo - provides a summary of a given field in a database, e.g. the record number, the last time it was updated, and what other records that given field is linked to in other Entrez databases\n",
    "* ESearch - takes a query and converts it to a list of UIDs that match that query, for a given database\n",
    "* EPost - accepts a list of UIDs and puts the corresponding data on the History Server; returns a query key and web environment that allows you to access the data from that server\n",
    "    * you should be using this for your AID search - since you know a certain list of AIDs that you're trying to downlaod the data from\n",
    "    * e.g. <code>epost.fcgi?db=database&id=uid1,uid2,uid3,...</code>\n",
    "* ESummary - accepts a list of UIDs and returns breif summaries of the resulting records\n",
    "* EFetch - accepts a list of UIDs and returns the data that are associated with each of the records, for a given database; _also allows for specifying data types_\n",
    "    * e.g. <code>efetch.fcgi?db=database&id=uid1,uid2,uid3&rettype=report_type&retmode=data_mode</code>\n",
    "* ELink - accepts a list of UIDs from one database and returns a way to find associated UIDs in that database or another, specified database \n",
    "* EGQuery - takes a query and searches across all Entrez databases - returns the number of records that match each query in each data base\n",
    "* ESpell - returns spelling suggestions for a given query at a given data base\n",
    "* ECitMatch - returns a list of PMIDs based on a list of formatted citation strings\n",
    "\n",
    "### understanding the E-utilities within Entrez\n",
    "* The E-utilities access Entrez databases - note that, occassionally, some data hosted by NCBI are not in the Entrez system; therefore, that data cannot be accessed by the E-utilities - verify if the data are in Entrez if that's the case\n",
    "* The entrez system identifies records via their UIDs - each database has its own UID set - see the table on this page for specifics\n",
    "    * __PubChem BioAssay UID__: AID ; __PubChem BioAssay Database Entrez Name__: pcassay\n",
    "\n",
    "__E-utilities syntax__\n",
    "> term1[field1] __Op__ term2[field2] __Op__ term3[field3] __Op__ ...\n",
    "\n",
    "    * term = search term\n",
    "    * [field] = type of value you're querying (e.g. [author] on pubmed)\n",
    "    * Op = operator (e.g. AND, OR, NOT)\n",
    "* Boolean oporators must be in all caps (e.g. OR)\n",
    "* all other terms should be in lowercase\n",
    "* spaces should be replaced with <code>+</code> in links e.g. <code>zhang[author]+AND+novartis[affiliation]</code>\n",
    "* use URL encodings for special characters (e.g. %22 for \")\n",
    "\n",
    "__Entrez History Server__\n",
    "* method for storing long lists of UIDs on a temporary server, so records associated with the UIDs can be processed in batches - _this is exactly what you should do with your project; obviates the need to do huge data batches at once, or multiple query calls; combined with EPost to locate a precise list of UIDs\n",
    "* the History server works by assigining a __query key__ (a specific ID) for the UIDs that correspond to a certain query and a __web environment__ (a cookie string related to where the data is being processed)\n",
    "* since the query key (i.e. the specific batch of UIDs) and the web environment (i.e. where the batches are processed) are separate, multiple data sets can be housed on the history server, and results can be combined between them using Boolean operators to discover data that's related across databases - however, this is not set by default, and has to be manually specified\n",
    "* History server works in 2x general steps (in the most simple case):\n",
    "    1. an upload step that generates a web environment and a query key (note that esearch requires usehistory=y, while epost uses the history server by default)\n",
    "> examples:\n",
    "esearch.fcgi?db=database&term=query&usehistory=y<br>\n",
    "epost.fcgi?db=database&id=uid1,uid2,uid3,...\n",
    "    2. a download step that leverages the web environment/query key to get the data you want\n",
    "> examples:\n",
    "esummary.fcgi?db=database&WebEnv=webenv&query_key=key<br>\n",
    "efetch.fcgi?db=database&WebEnv=webenv&query_key=key&rettype=report_type&retmode=data_mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Applications of E-utilities\n",
    "https://www.ncbi.nlm.nih.gov/books/NBK25498/\n",
    "\n",
    "from above, I think what I want to do is combine two protocols from these sample applications:\n",
    "<code>EPost-EFetch</code> to download recrods associated with a specific list of UIDs\n",
    "\n",
    "and the <code>application 3: retrieving large datasets</code> section, which uses the history server to retrieve data from EFetch in batches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__EPost - Esummary/Efetch example:__\n",
    "\n",
    "        use LWP::Simple;\n",
    "\n",
    "        # Download protein records corresponding to a list of GI numbers.\n",
    "\n",
    "        $db = 'protein';\n",
    "        $id_list = '194680922,50978626,28558982,9507199,6678417';\n",
    "\n",
    "        #assemble the epost URL\n",
    "        $base = 'https://eutils.ncbi.nlm.nih.gov/entrez/eutils/';\n",
    "        $url = $base . \"epost.fcgi?db=$db&id=$id_list\";\n",
    "\n",
    "        #post the epost URL\n",
    "        $output = get($url);\n",
    "\n",
    "        #parse WebEnv and QueryKey\n",
    "        $web = $1 if ($output =~ /<WebEnv>(\\S+)<\\/WebEnv>/);\n",
    "        $key = $1 if ($output =~ /<QueryKey>(\\d+)<\\/QueryKey>/);\n",
    "\n",
    "        ### include this code for EPost-ESummary\n",
    "        #assemble the esummary URL\n",
    "        $url = $base . \"esummary.fcgi?db=$db&query_key=$key&WebEnv=$web\";\n",
    "\n",
    "        #post the esummary URL\n",
    "        $docsums = get($url);\n",
    "        print \"$docsums\";\n",
    "\n",
    "        ### include this code for EPost-EFetch\n",
    "        #assemble the efetch URL\n",
    "        $url = $base . \"efetch.fcgi?db=$db&query_key=$key&WebEnv=$web\";\n",
    "        $url .= \"&rettype=fasta&retmode=text\";\n",
    "\n",
    "        #post the efetch URL\n",
    "        $data = get($url);\n",
    "        print \"$data\";\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "conda update pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import record list\n",
    "p = '../data/literature/KYHelal_etal_2016_JCIM_supplement.xlsx'\n",
    "supp_table = pd.read_excel(p, engine='openpyxl')\n",
    "supp_table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# translating the code into python and tailoring it for PubChem BioAssay\n",
    "\n",
    "# assemble db name and UID list\n",
    "db = 'pcassay'\n",
    "id_list = supp_table['AID'].values\n",
    "id_list = id_list[0:5]\n",
    "\n",
    "id_string = ''\n",
    "for s in id_list:\n",
    "    id_string = id_string + str(s) + ','\n",
    "id_string = id_string[:-1]\n",
    "\n",
    "#assemble the epost URL\n",
    "base = 'https://eutils.ncbi.nlm.nih.gov/entrez/eutils/'\n",
    "url = base + \"epost.fcgi?db={db}&id={id_string}\".format(db = db, id_string = id_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# post the UIDs and parse the resulting response object to get the query_key and web_env\n",
    "r = requests.get(url)\n",
    "content = r.content\n",
    "\n",
    "root = ET.fromstring(content)\n",
    "key = root.find('QueryKey').text\n",
    "web_env = root.find('WebEnv').text\n",
    "\n",
    "#retmax_value = 500\n",
    "#retstart_value = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch data\n",
    "#assemble the efetch URL\n",
    "fetch_url = base + \"efetch.fcgi?db={db}&query_key={key}&WebEnv={web_env}\".format(db = db,\n",
    "                                                                                 key = key,\n",
    "                                                                                 web_env = web_env)\n",
    "fetch_url = fetch_url + \"&rettype=datatable&actvty=all&retmode=csv\"\n",
    "fetch_url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "example url when trying to download 1x record using the pubchem bioassay gui\n",
    "https://pubchem.ncbi.nlm.nih.gov/assay/pcget.cgi?query=download&record_type=datatable&actvty=all&response_type=save&aid=1511\n",
    "\n",
    "hmmm ... the above code isn't working ... I can't tell what rettype I should pass to the entrez url\n",
    "\n",
    "let's try just using the above url:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_url_base = 'https://pubchem.ncbi.nlm.nih.gov/assay/pcget.cgi?query=download&record_type=datatable&actvty=all&response_type=save&aid='\n",
    "data_dir = '../data/test_download/'\n",
    "\n",
    "for i in id_list:\n",
    "    dl_url = dl_url_base + str(i)\n",
    "    temp_df = pd.read_csv(dl_url)\n",
    "    temp_df.to_csv(data_dir + str(i)+'.csv')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "that  - technically worked ... although it was very slow and feels sketchy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:qsar]",
   "language": "python",
   "name": "conda-env-qsar-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
